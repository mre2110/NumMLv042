{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grundlagen der Optimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Überblick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt betrachten wir verschiedene Methoden aus der Analysis\n",
    "zur Behandlung von Optimierungsproblemen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grundlagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir betrachten eine Zielfunktion $f:\\mathbb{R} ^{d}\\rightarrow \\mathbb{R}$. Minimiert man\n",
    "\n",
    "- $f$ über ganz $\\mathbb{R}^d$, so liegt ein \n",
    "  *nicht restringiertes* Problem vor\n",
    "\n",
    "- $f$ über $\\emptyset \\neq X\\subset \\mathbb{R} ^{d}$, so handelt es \n",
    "  sich um ein *restringiertes* Problem\n",
    "\n",
    "Ist $f(x) \\ge c > -\\infty$, so existiert $f_\\ast = \\inf_x f$, \n",
    "  aber nicht notwendig ein $x_\\ast$ mit $f(x_\\ast)=\\inf_x f = f_\\ast$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beispiel:** \n",
    "\n",
    "- für $f( x) =e^{-x^{2}}$, $x \\in \\mathbb{R}$, ist\n",
    "  \\begin{equation*} \n",
    "  \\inf _{x\\in \\mathbb{R} }f\\left( x\\right) =0\n",
    "  \\end{equation*}\n",
    "  aber es gibt kein $x_{\\ast }\\in \\mathbb{R}$ mit\n",
    "  $f( x_{\\ast }) =0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ist $f$ stetig, $X\\subset \\mathbb{R} ^{d}$ kompakt, dann hat das restringierte Problem (mindestens) eine Lösung, d.h.\n",
    "\\begin{equation*} \n",
    "\\text{argmin}_{x\\in X}f(x) \\neq \\emptyset \n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nicht restringierte Probleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nicht restringierten Fall erhält man bei (ausreichend oft) differenzierbarer Zielfunktion $f$ notwendige und hinreichende Bedingungen für (lokale) Minimalstellen.\n",
    "\n",
    "Ist $x_\\ast \\in \\text{argmin}_{x\\in \\mathbb{R} ^{d}}f(x)$, dann gelten die notwendigen Bedingungen:\n",
    "\n",
    "- ist $f\\in C^{1}( \\mathbb{R} ^{d})$ \n",
    "    $\\Rightarrow$ $f'( x_{\\ast }) =0$ \n",
    "    \n",
    "- ist $f\\in C^{2}( \\mathbb{R} ^{d})$ \n",
    "    $\\Rightarrow$ $f'( x_{\\ast }) =0$ und $f''( x_{\\ast })$ ist positiv semidefinit\n",
    "    \n",
    "Als hinreichende Bedingungen erhalten wir für $f\\in C^{2}( \\mathbb{R} ^{d})$:\n",
    "\n",
    "- ist $f'(\\tilde{x}) =0$ und $f''(\\tilde{x})$ positiv definit\n",
    "  oder $f''(x)$ in einer offenen Umgebung $U$ von $\\tilde{x}$ positiv semidefinit, \n",
    "  dann gilt \n",
    "  \\begin{equation*} \n",
    "  \\tilde{x} \\in \\text{argmin}_{x\\in U}f(x), \n",
    "  \\end{equation*}\n",
    "  d.h. $\\tilde{x}$ ist lokales Minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restringierte Probleme, Lagrange-Funktion, KKT-Bedingungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Äquivalent zu den obigen Ergebnissen bei der restringierten Optimierung sind die \n",
    "[*Karush-Kuhn-Tucker-Bedingungen*](https://de.wikipedia.org/wiki/Karush-Kuhn-Tucker-Bedingungen).\n",
    "\n",
    "Wir betrachten das Optimierungsproblem\n",
    "\\begin{equation*} \n",
    "\\min _{x\\in X}f(x),\n",
    "\\quad\n",
    "g(x) \\leq 0,\n",
    "\\quad\n",
    "h(x) =0,\n",
    "\\end{equation*}\n",
    "mit $\\emptyset\\neq X \\subset \\mathbb{R} ^{d}$ und\n",
    "\\begin{equation*} \n",
    "f:X\\rightarrow \\mathbb{R} ,\n",
    "\\quad\n",
    "g:X\\rightarrow \\mathbb{R} ^{m},\n",
    "\\quad\n",
    "h:X\\rightarrow \\mathbb{R} ^{p}.\n",
    "\\end{equation*}\n",
    "\n",
    "Wir nehmen an, dass $f,g,h \\in C^1(X)$ und definieren die zugehörige *Lagrange-Funktion* $L$ durch\n",
    "\\begin{equation*} \n",
    "L\\left( x,\\lambda ,\\mu \\right) =f\\left( x\\right) +\\lambda ^{T}g\\left( x\\right) +\\mu ^{T}h\\left( x\\right). \n",
    "\\end{equation*}\n",
    "\n",
    "$x_\\ast,\\lambda_\\ast,\\mu_\\ast$ heißt KKT-Punkt, falls\n",
    "\\begin{equation*} \n",
    "\\begin{aligned}\\partial _{x}L\\left( x_{\\ast },\\lambda _{\\ast },\\mu _{\\ast }\\right) &=0,\\\\ \n",
    "g\\left( x_{\\ast }\\right) &\\leq 0\\\\ \n",
    "h\\left( x_{\\ast}\\right) &=0,\\\\ \n",
    "\\lambda _{\\ast } &\\geq 0,\\\\ \n",
    "\\lambda _{\\ast,i }g_i\\left( x_{\\ast }\\right) &=0 \\quad \\forall i\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "Ist $x_\\ast$ eine Lösung des Optimierungsproblems und erfüllt gewisse Regularitätsbedingungen (Constraint-Qualifications), dann existieren $\\lambda_\\ast \\geq 0, \\mu_\\ast$, so dass $x_\\ast,\\lambda_\\ast,\\mu_\\ast$ ein KKT-Punkt ist.\n",
    "Wir haben es hier also mit notwendige Bedingungen zu tun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sind $X, f, g_i$ konvex und $h$ linear affin, dann vereinfacht sich das ganze noch:\n",
    "\n",
    "- als Constraint-Qualification muss nur die \n",
    "  *Slater-Bedingung* gelten, d.h.\n",
    "  \\begin{equation*} \n",
    "  \\exists \\tilde{x}\\in X \n",
    "  \\quad\\text{mit}\\quad\n",
    "  g( \\tilde{x}) <0,\n",
    "  \\quad\n",
    "  h( \\tilde{x})=0\n",
    "  \\end{equation*}\n",
    "  \n",
    "- KKT ist auch hinreichend, d.h.$x_\\ast$ ist lokales (und damit auch \n",
    "  globales) Minimum, ohne weitere Annahmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beispiel:**\n",
    "\n",
    "- wir betrachten das Problem\n",
    "  \\begin{equation*} \n",
    "  \\min_{x\\in \\mathbb{R}^{2},\\ x_{1}^{2}+x_{2}^{2}\\leq 1,\\ x_{1}=x_{2}}x_1\n",
    "  \\end{equation*}\n",
    "  \n",
    "- mit $X=\\mathbb{R}^{2}$,\n",
    "  \\begin{equation*} \n",
    "  f(x) = x_1, \\quad g(x) = x_{1}^{2}+x_{2}^{2}-1, \\quad h(x) = x_1 - x_2\n",
    "  \\end{equation*}\n",
    "  erhalten wir die Standardform\n",
    "  \\begin{equation*} \n",
    "  \\min _{x\\in X}f(x),\n",
    "  \\quad\n",
    "  g(x) \\leq 0,\n",
    "  \\quad\n",
    "  h(x) =0\n",
    "  \\end{equation*}\n",
    "  \n",
    "- $X,f,g$ sind konvex, $h$ ist linear affin und die Slater-Bedingung ist ebenfalls erfüllt\n",
    "  \n",
    "- als Lagrange-Funktion erhalten wir\n",
    "  \\begin{equation*} \n",
    "  L(x,\\lambda,\\mu) = x_1 + \\lambda(x_{1}^{2}+x_{2}^{2}-1) + \\mu (x_1 - x_2)\n",
    "  \\end{equation*}\n",
    "  und somit\n",
    "  \\begin{align*}\n",
    "  \\partial_{x}L(x,\\lambda ,\\mu) &=\n",
    "  \\begin{pmatrix} 1 +2\\lambda x_{1} +\\mu \\\\ 2\\lambda x_{2} -\\mu \\end{pmatrix} =0, \\\\\n",
    "  g\\left( x\\right) &=x_{1}^{2}+x_{2}^{2}-1\\leq 0,\\\\ \n",
    "  h\\left( x\\right) &=x_{1}-x_{2}=0,\\\\ \n",
    "  \\lambda g\\left( x\\right) &=\\lambda \\left( x_{1}^{2}+x_{2}^{2}-1\\right) =0\n",
    "  \\end{align*}\n",
    "  \n",
    "- subtrahiert man im Gradienten die zweite von der ersten Gleichung, so folgt\n",
    "  \\begin{equation*} \n",
    "  1+2\\lambda \\left( x_{1}-x_{2}\\right) +2\\mu =0\n",
    "  \\end{equation*}\n",
    "  und wegen $x_{1}-x_{2}=0$ schließlich\n",
    "  \\begin{equation*} \n",
    "  \\mu =-\\dfrac{1}{2}\n",
    "  \\end{equation*}\n",
    "  \n",
    "- eingesetzt in die zweite Komponente des Gradienten erhalten wir\n",
    "  \\begin{equation*} \n",
    "  \\lambda x_{2}=\\dfrac{\\mu }{2}=-\\dfrac{1}{4}\n",
    "  \\end{equation*}\n",
    "  \n",
    "- aus $\\lambda \\geq 0$ folgt daraus $\\lambda > 0$ und \n",
    "    \\begin{equation*} \n",
    "    x_2 < 0\n",
    "    \\end{equation*}\n",
    "    und wegen $\\lambda \\left( x_{1}^{2}+x_{2}^{2}-1\\right) =0$ somit\n",
    "    \\begin{equation*} \n",
    "    x_{1}^{2}+x_{2}^{2} = 1\n",
    "    \\end{equation*}\n",
    "    \n",
    "- außerdem soll noch die Gleichheitsbedingung\n",
    "  \\begin{equation*} \n",
    "  x_1 = x_2\n",
    "  \\end{equation*}\n",
    "  gelten\n",
    "  \n",
    "- insgesamt erhalten wir damit\n",
    "  \\begin{equation*} \n",
    "  x_{2}=-\\dfrac{1}{\\sqrt{2}}\n",
    "  \\end{equation*}\n",
    "  und somit ist\n",
    "  \\begin{equation*} \n",
    "  x_{\\ast }=-\\dfrac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n",
    "  \\end{equation*}\n",
    "  wegen der Konvexität und der Slater-Bedingung die (eindeutige) Lösung des Optimierungsproblems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nicht-konvexen Fall gelten für $f,g,h \\in C^2$ folgende hinreichende Bedingungen:\n",
    "\n",
    "- ist $x_\\ast,\\lambda_\\ast,\\mu_\\ast$ ein KKT-Punkt und gilt\n",
    "  \\begin{equation*} \n",
    "  s^{T}\\partial _{x}^{2}L\\left( x_{\\ast },\\lambda _{\\ast },\\mu_\\ast \\right) s\\geq 0\n",
    "  \\end{equation*}\n",
    "  für alle $s\\neq 0$ mit\n",
    "  \\begin{equation*} \n",
    "  \\begin{pmatrix} \n",
    "  \\partial _{x}g_{i}\\left( x_{\\ast }\\right) \\\\     \n",
    "  \\partial _{x}h_{j}\\left( x_{\\ast }\\ \\right)\n",
    "  \\end{pmatrix}^{T}\n",
    "  s=0\n",
    "  \\end{equation*} \n",
    "  mit $i$ s.d. $\\lambda_{\\ast,i}>0$,\n",
    "  dann ist $x_\\ast$ ein lokales Minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dualität"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir betrachten das primale Problem\n",
    "\\begin{equation*} \n",
    "\\min _{x\\in X}f(x),\n",
    "\\quad\n",
    "g(x) \\leq 0,\n",
    "\\quad\n",
    "h(x) =0,\n",
    "\\end{equation*} \n",
    "die zugehörige Lagrange-Funktion\n",
    "\\begin{equation*} \n",
    "L( x,\\lambda ,\\mu ) \n",
    "= f(x) +\\lambda ^{T}g(x) +\\mu ^{T}h(x) \n",
    "\\end{equation*}\n",
    "und definieren damit die *duale Funktion*\n",
    "\\begin{equation*} \n",
    "q( \\lambda ,\\mu ) =\\inf _{x\\in X} L( x,\\lambda ,\\mu ). \n",
    "\\end{equation*}\n",
    "\n",
    "Für $q$ untersuchen wir das duale Problem\n",
    "\\begin{equation*} \n",
    "\\max_{\\lambda \\geq 0,\\mu }q( \\lambda ,\\mu )\n",
    "\\end{equation*}\n",
    "über dem *wesentlichen Zulässigkeitsbereich*\n",
    "\\begin{equation*} \n",
    "\\mathrm{dom}_{q}=\\big\\{ ( \\lambda ,\\mu )\\ \\big|\\  \\lambda \\geq 0,\\ q( \\lambda ,\\mu ) >-\\infty \\big\\}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das duale Problem hat folgende Eigenschaften:\n",
    "\n",
    "  - $\\mathrm{dom}_{q}$ ist immer konvex\n",
    "  \n",
    "  - $-q$ ist immer konvex\n",
    "  \n",
    "  - ist \n",
    "    \\begin{equation*} \n",
    "    R_{p}=\\big\\{ x \\ \\big| \\ g( x) \\leq 0,h( x) = 0\\big\\} \n",
    "    \\end{equation*} \n",
    "    der zulässige Bereich des primalen Problems, dann gilt\n",
    "    \\begin{equation*} \n",
    "    \\sup_{\\mathrm{dom}_{q}} q\\left( \\lambda ,\\mu \\right) \\leq \\inf_{R_{p}} f( x)\n",
    "    \\end{equation*}\n",
    "    \n",
    "    und somit gilt für alle Lösungen $\\lambda_\\ast, \\mu_\\ast$ von \n",
    "    $\\sup_{\\mathrm{dom}_{q}} q\\left( \\lambda ,\\mu \\right)$ und $x_\\ast$\n",
    "    von $\\inf_{R_{p}} f( x)$\n",
    "    \\begin{equation*} \n",
    "    q(\\lambda_\\ast, \\mu_\\ast) \\leq f(x_\\ast).\n",
    "    \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Differenz\n",
    "\\begin{equation*} \n",
    "f(x_\\ast) - q(\\lambda_\\ast, \\mu_\\ast) \\ge 0\n",
    "\\end{equation*}\n",
    "bezeichnet man als *Dualitäts-Lücke*.\n",
    "Gilt\n",
    "\\begin{equation*} \n",
    "f(x_\\ast) - q(\\lambda_\\ast, \\mu_\\ast) = 0\n",
    "\\end{equation*}\n",
    "so spricht man von starker Dualität:\n",
    "\n",
    "- starke Dualität gilt nicht immer\n",
    "\n",
    "- sind $f,g$ konvex, $h$ linear affin und die Slater-Bedingung erfüllt, \n",
    "  dann gilt starke Dualität\n",
    "  \n",
    "Praktischer Einsatz:\n",
    "\n",
    "- ist nur der Wert $f_\\ast = f(x_\\ast)$ (und nicht $x_\\ast$) interessant, \n",
    "  dann kann man statt des primalen das duale Problem lösen, das immer konvex ist\n",
    "  \n",
    "- ist $\\bar{x}$ eine Näherung von $x_\\ast$ und gilt starke Dualität, so kann man mit Hilfe geeignet gewählter $\\bar{\\lambda},\\bar{\\mu}$ über\n",
    "  \\begin{equation*} \n",
    "  f(\\bar{x}) - q(\\bar{\\lambda},\\bar{\\mu})\n",
    "  \\end{equation*}\n",
    "  einen Fehlerindikator für $\\bar{x}$ berechnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beispiel:**\n",
    "\n",
    "- wir betrachten\n",
    "  \\begin{equation*} \n",
    "  \\min _{x\\in \\mathbb{R} ^{d}} c^{T}x,\n",
    "  \\quad Ax-b\\leq 0,\n",
    "  \\quad A\\in \\mathbb{R} ^{m\\times d}\n",
    "  \\end{equation*}\n",
    "  \n",
    "- als Lagrange-Funktion erhalten wir mit $\\lambda \\in \\mathbb{R}^m$,\n",
    "  $\\lambda \\geq 0$\n",
    "  \\begin{align*} \n",
    "  L(x,\\lambda) \n",
    "  &= c^{T}x+\\lambda ^{T}( Ax-b) \\\\\n",
    "  &=( c^{T}+\\lambda ^{T}A) x - \\lambda ^{T}b\n",
    "  \\end{align*}\n",
    "  bzw. mit $y = c + A^T \\lambda$\n",
    "  \\begin{align*} \n",
    "  L(x,\\lambda) \n",
    "  &=y^T x - \\lambda ^{T}b  \n",
    "  \\end{align*}\n",
    "  \n",
    "- jetzt berechnen wir die duale Funktion\n",
    "  \\begin{equation*} \n",
    "  q(\\lambda) =\\inf _{x\\in \\mathbb{R}^d} L( x, \\lambda) \n",
    "  \\end{equation*}\n",
    "\n",
    "- $L$ ist linear affin in $x$ mit\n",
    "    \\begin{equation*} \n",
    "    \\partial_x L(x,\\lambda) = y^T\n",
    "    \\end{equation*}\n",
    "    \n",
    "- ist $y \\neq 0$ so erhalten wir mit $x = \\nu y$\n",
    "    \\begin{equation*} \n",
    "      L(x,\\lambda) \n",
    "      = \\nu \\|y\\|_2^2 - \\lambda ^{T}b   \n",
    "      \\xrightarrow{\\nu\\to-\\infty}-\\infty\n",
    "    \\end{equation*}\n",
    "    \n",
    "- für $y=0$ (also $\\partial_x L(x,\\lambda) = 0$) \n",
    "  gilt\n",
    "    \\begin{equation*} \n",
    "      L(x,\\lambda) \n",
    "      = - \\lambda ^{T}b\n",
    "      = \\inf _{x\\in \\mathbb{R}^d} L( x, \\lambda) \n",
    "    \\end{equation*}\n",
    "\n",
    "- somit ist\n",
    "  \\begin{equation*} \n",
    "  q(\\lambda) \n",
    "  =\\begin{cases}\n",
    "  -\\lambda ^{T}b & \\text{für }c + A^T \\lambda=0\\\\ \n",
    "  -\\infty & \\text{sonst}\\end{cases}\n",
    "  \\end{equation*}\n",
    "  und das duale Problem hat die Form\n",
    "  \\begin{equation*} \n",
    "  \\max_{\\lambda \\in \\mathbb{R} ^{m}}(-\\lambda ^{T}b),\n",
    "  \\quad \\lambda \\geq 0,\n",
    "  \\quad A^{T}\\lambda =-c\n",
    "  \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beispiel:** \n",
    "\n",
    "- wir leiten jetzt die duale Form des Optimierungsproblems \n",
    "  bei Support-Vector Classifiern her, die wir oben im Zusammenhang mit \n",
    "  dem Kernel-Trick benutzt haben\n",
    "\n",
    "- das primale Problem lautet\n",
    "    \\begin{equation*} \n",
    "    \\min_{v\\neq 0, v_0,\\xi}\n",
    "    \\Big(\n",
    "    \\frac{1}{2}\\|v\\|_2^2\n",
    "    + C \\sum_{i=1}^n \\xi_i\n",
    "    \\Big)\n",
    "    \\end{equation*}\n",
    "    mit\n",
    "    \\begin{equation*} \n",
    "    y_i(v^T x_i + v_0)  \\geq 1 - \\xi_i, \n",
    "    \\quad\n",
    "    \\xi_i\\geq 0,\n",
    "    \\quad i = 1,\\ldots,n.\n",
    "    \\end{equation*}\n",
    "    \n",
    "- setzen wir\n",
    "    \\begin{align*} \n",
    "    w \n",
    "    &= (v,v_0,\\xi) \\in X = \\mathbb{R}^{m + 1 + n} \\\\\n",
    "    f(w) \n",
    "    &= \\frac{1}{2}\\|v\\|_2^2 + C \\sum_{i=1}^n \\xi_i \\\\\n",
    "    g_i(w) \n",
    "    &= -\\Big(y_i \\big(\\sum_{j=1}^m v_j x_{ij} + v_0 \\big) - 1 + \\xi_i \\Big),   \n",
    "    \\quad i=1,\\ldots,n\\\\\n",
    "    g_i(w) \n",
    "    &= - \\xi_i, \n",
    "    \\quad i=n+1,\\ldots,2n\n",
    "    \\end{align*}\n",
    "  so erhalten wir die Standardform\n",
    "    \\begin{align*} \n",
    "   \\min _{w\\in \\mathbb{R}^{m + 1 + n}}f(w),\n",
    "    \\quad\n",
    "    g(w) \\leq 0\n",
    "    \\end{align*}      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mit $\\lambda = (\\alpha, \\beta)$, $\\alpha,\\beta \\geq 0$, folgt für \n",
    "  die Lagrange-Funktion\n",
    "    \\begin{align*} \n",
    "    L(w,\\lambda) =&\n",
    "    L(v, v_0, \\xi, \\alpha, \\beta) \\\\\n",
    "    = &\n",
    "    \\frac{1}{2}\\|v\\|_2^2\n",
    "    + C \\sum_{i=1}^n \\xi_i\n",
    "    \\\\\n",
    "    &- \\sum_{i=1}^n \\alpha_i  \\Big(y_i \\big(\\sum_{j=1}^m v_j x_{ij} + v_0 \\big) - 1 + \\xi_i \\Big)\\\\\n",
    "    &- \\sum_{i=1}^n\\beta_i \\xi_i\\\\\n",
    "    = &\n",
    "    \\frac{1}{2}\\|v\\|_2^2\n",
    "    - \\sum_{i=1}^n \\alpha_i y_i \\sum_{j=1}^m v_j x_{ij} \n",
    "    \\\\\n",
    "    &- v_0\\sum_{i=1}^n \\alpha_i  y_i \n",
    "    \\\\\n",
    "    &+ \\sum_{i=1}^n (C-\\alpha_i - \\beta_i) \\xi_i \n",
    "    \\\\\n",
    "    &+ \\sum_{i=1}^n \\alpha_i\n",
    "    \\end{align*}\n",
    "  bzw. für die duale Funktion\n",
    "    \\begin{align*} \n",
    "    q(\\alpha,\\beta) \n",
    "    = \\inf_{(v, v_0, \\xi)\\in \\mathbb{R}^{m + 1 + n}} L(v, v_0, \\xi, \\alpha, \\beta) \n",
    "    \\end{align*}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $L$ ist quadratisch in $v$ und linear affin in $v_0$ \n",
    "  und $\\xi$ (und somit konvex und differenzierbar)\n",
    "  \n",
    "- wie im vorherigen Beispiel folgt, dass $q(\\alpha,\\beta)$\n",
    "  nur dann größer $-\\infty$ sein kann, wenn\n",
    "    \\begin{align*}\n",
    "    0 = \\partial_{v_0} L(v, v_0, \\xi, \\alpha, \\beta) \n",
    "    &= - \\sum_{i=1}^n \\alpha_i y_i, \n",
    "    \\\\\n",
    "    0 = \\partial_{\\xi_i} L(v, v_0, \\xi, \\alpha, \\beta) \n",
    "    &= \n",
    "    C - \\alpha_i - \\beta_i,\n",
    "    \\quad i = 1,\\ldots,n,\n",
    "    \\end{align*}\n",
    "  gilt, insgesamt also\n",
    "  \\begin{align*}\n",
    "  \\alpha_i,\\beta_i\\geq 0,\n",
    "  \\quad\n",
    "  \\sum_{i=1}^n \\alpha_i y_i = 0, \n",
    "  \\quad\n",
    "  \\alpha_i + \\beta_i = C\n",
    "  \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- unter diesen Einschränkungen vereinfacht sich $L$ zu\n",
    "    \\begin{align*} \n",
    "    L(v, v_0, \\xi, \\alpha, \\beta)\n",
    "    =\n",
    "    \\frac{1}{2}\\|v\\|_2^2\n",
    "    - \\sum_{i=1}^n \\alpha_i y_i \\sum_{j=1}^m v_j x_{ij} \n",
    "    &+ \\sum_{i=1}^n \\alpha_i,\n",
    "    \\end{align*}\n",
    "  ist also insbesondere unabhängig von $v_0, \\xi, \\beta$\n",
    "  und wird bei gegebenem $\\alpha$ minimal an $\\hat{v}$ mit\n",
    "    \\begin{align*}\n",
    "    0 = \\partial_{v_k} L(\\hat{v}, v_0, \\xi, \\alpha, \\beta) \n",
    "    &= \n",
    "    \\hat{v}_k\n",
    "    - \\sum_{i=1}^n \\alpha_i y_i x_{ik},\n",
    "    \\quad k = 1,\\ldots,m,\n",
    "    \\end{align*}\n",
    "  also\n",
    "  \\begin{align*}\n",
    "  \\hat{v}_k &= \\sum_{i=1}^n \\alpha_i y_i x_{ik}.\\\\\n",
    "  \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- eingesetzt in $L$ erhalten wir damit\n",
    "    \\begin{align*} \n",
    "    q(\\alpha,\\beta) \n",
    "    & =   L(\\hat{v}, v_0, \\xi, \\alpha, \\beta)\n",
    "    \\\\\n",
    "    & = \n",
    "    \\frac{1}{2}\\|\\hat{v}\\|_2^2\n",
    "    - \\sum_{i=1}^n \\alpha_i y_i \\sum_{j=1}^m \\hat{v}_j x_{ij} \n",
    "    + \\sum_{i=1}^n \\alpha_i\n",
    "    \\\\\n",
    "    & =\n",
    "    \\frac{1}{2}\\sum_{j=1}^m \\hat{v}_j^2\n",
    "    - \\sum_{j=1}^m \\hat{v}_j\\sum_{i=1}^n \\alpha_i y_i  x_{ij} \n",
    "      +  \\sum_{i=1}^n \\alpha_i \n",
    "      \\\\\n",
    "    & =\n",
    "    \\frac{1}{2}\\sum_{j=1}^m \\hat{v}_j^2\n",
    "     - \\sum_{j=1}^m \\hat{v}_j^2\n",
    "      +  \\sum_{i=1}^n \\alpha_i \n",
    "      \\\\\n",
    "    & =\n",
    "    -\\frac{1}{2}\\sum_{j=1}^m \\hat{v}_j^2\n",
    "      +  \\sum_{i=1}^n \\alpha_i \n",
    "      \\\\\n",
    "    & =\n",
    "    -\\frac{1}{2}\n",
    "    \\sum_{j=1}^m \\big(\\sum_{i=1}^n \\alpha_i y_i  x_{ij} \\big)^2\n",
    "      +  \\sum_{i=1}^n \\alpha_i \\\\\n",
    "    & =\n",
    "    -\\frac{1}{2}\n",
    "    \\sum_{i=1}^n \\sum_{k=1}^n \n",
    "    \\alpha_i y_i \n",
    "    \\big( \\sum_{j=1}^m x_{ij} x_{kj}\\big)\n",
    "    y_k\\alpha_k \n",
    "     +  \\sum_{i=1}^n \\alpha_i \n",
    "    \\end{align*}  \n",
    "  bzw.\n",
    "    \\begin{equation*} \n",
    "    q(\\alpha,\\beta) =\n",
    "    -\\frac{1}{2}\\alpha^T Q \\alpha + e^T \\alpha \n",
    "    \\end{equation*}\n",
    "    mit\n",
    "    \\begin{align*} \n",
    "    Q = \\big( y_i x_i^T x_k y_k \\big)_{i,k = 1,\\ldots,n},\n",
    "    \\quad\n",
    "    e = (1,\\ldots,1)^T\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- insgesamt erhalten wir für die duale Funktion $q$ für\n",
    "  $\\alpha,\\beta\\geq 0$\n",
    "  \\begin{align*}\n",
    "  q(\\alpha,\\beta) \n",
    "  =\n",
    "  \\begin{cases}\n",
    "      -\\frac{1}{2}\\alpha^T Q \\alpha + e^T \\alpha \n",
    "      & \\text{für} \\quad y^T\\alpha = 0, \\quad \\alpha + \\beta = Ce \\\\\n",
    "      - \\infty & \\text{sonst}\n",
    "  \\end{cases}\n",
    "  \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- als duales Problem haben wir damit\n",
    "  \\begin{align*}\n",
    "  \\max_{\\alpha\\geq 0, \\beta\\geq 0}q(\\alpha,\\beta)\n",
    "  = \\min_{\\alpha\\geq 0} \n",
    "    \\big(\\frac{1}{2}\\alpha^T Q \\alpha - e^T \\alpha \\big)\n",
    "  \\end{align*}\n",
    "  unter den Nebenbedingungen\n",
    "  \\begin{align*}\n",
    "  y^T \\alpha = 0,\n",
    "  \\quad \\alpha_i + \\beta_i = C \\quad \\forall i\n",
    "  \\end{align*}\n",
    "\n",
    "- da $\\beta_i \\geq 0$ nur in die Nebenbedingung eingeht,\n",
    "  kann diese auf $0\\leq \\alpha_i \\leq C$ geändert werden\n",
    "  \n",
    "- somit erhalten wir die finale Form des dualen Problems,\n",
    "  wie wir sie bei den Support-Vector Classifiern bereits \n",
    "  benutzt haben: \n",
    "    \\begin{equation*} \n",
    "    \\min_{\\alpha \\geq 0}\n",
    "    \\Big(\n",
    "    \\frac{1}{2}\\alpha^T Q \\alpha - e^T \\alpha \n",
    "    \\Big)\n",
    "    \\end{equation*}\n",
    "    mit\n",
    "    \\begin{equation*} \n",
    "    Q = \\big( y_i x_i^T x_jy_j \\big)_{i,j = 1,\\ldots,n},\n",
    "    \\quad\n",
    "    y^T \\alpha = 0,\n",
    "    \\quad\n",
    "    0\\leq \\alpha \\leq Ce.\n",
    "    \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für nicht-restringierte bzw, restringierte Optimierungsprobleme haben wir die Werkzeuge\n",
    "aus der Analysis betrachtet, u.a. Lagrange-Funktion, KKT-Bedingungen und duale Probleme."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "fr",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": false,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
