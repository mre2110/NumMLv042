
<!DOCTYPE html>

<html lang="de">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Grundlagen der Optimierung &#8212; Numerische Algorithmen für Maschinelles Lernen WS21/22 (Version 0.42)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Stichwortverzeichnis" href="genindex.html" />
    <link rel="search" title="Suche" href="search.html" />
    <link rel="next" title="Konvexität" href="09_Konvexitaet.html" />
    <link rel="prev" title="Topic Extraction, NMF" href="07_Topic_Extraction.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="de">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Numerische Algorithmen für Maschinelles Lernen WS21/22 (Version 0.42)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Dieses Buch durchsuchen ..." aria-label="Dieses Buch durchsuchen ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="00_Vorwort.html">
   Numerische Algorithmen für Maschinelles Lernen (Version 0.422)
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_Regression.html">
   Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_Dimensionsreduktion.html">
   Dimensionsreduktion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_Regularisierung.html">
   Regularisierung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_Background_Removal_QR.html">
   Background Removal mit TSVD
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_Klassifikation_mit_SVM.html">
   Support-Vector Klassifikation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_Neuronale_Netze.html">
   Neuronale Netze
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_Topic_Extraction.html">
   Topic Extraction, NMF
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Grundlagen der Optimierung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09_Konvexitaet.html">
   Konvexität
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_Gradient_Descent.html">
   Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_Projected_Gradient_Descent.html">
   Projected Gradient-Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12_Subgradient_Descent.html">
   Subgradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="13_Proximal_Gradient_Descent.html">
   Proximal Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14_Stochastic_Gradient_Descent.html">
   Stochastic Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15_Probabilistische_Lineare_Algebra.html">
   Probabilistische Lineare Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="99_Literatur.html">
   Weiterführende Links
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Navigation umschalten" aria-controls="site-navigation"
                title="Navigation umschalten" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Laden Sie diese Seite herunter"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/08_Grundlagen_Optimierung.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Quelldatei herunterladen" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="In PDF drucken"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Vollbildmodus"
        title="Vollbildmodus"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/mre2110/NumMLv042/master?urlpath=tree/08_Grundlagen_Optimierung.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Starten Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Inhalt
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uberblick">
   Überblick
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#grundlagen">
   Grundlagen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nicht-restringierte-probleme">
   Nicht restringierte Probleme
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#restringierte-probleme-lagrange-funktion-kkt-bedingungen">
   Restringierte Probleme, Lagrange-Funktion, KKT-Bedingungen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dualitat">
   Dualität
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zusammenfassung">
   Zusammenfassung
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Grundlagen der Optimierung</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Inhalt </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uberblick">
   Überblick
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#grundlagen">
   Grundlagen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nicht-restringierte-probleme">
   Nicht restringierte Probleme
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#restringierte-probleme-lagrange-funktion-kkt-bedingungen">
   Restringierte Probleme, Lagrange-Funktion, KKT-Bedingungen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dualitat">
   Dualität
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zusammenfassung">
   Zusammenfassung
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="grundlagen-der-optimierung">
<h1>Grundlagen der Optimierung<a class="headerlink" href="#grundlagen-der-optimierung" title="Link zu dieser Überschrift">¶</a></h1>
<div class="section" id="uberblick">
<h2>Überblick<a class="headerlink" href="#uberblick" title="Link zu dieser Überschrift">¶</a></h2>
<p>In diesem Abschnitt betrachten wir verschiedene Methoden aus der Analysis
zur Behandlung von Optimierungsproblemen.</p>
</div>
<div class="section" id="grundlagen">
<h2>Grundlagen<a class="headerlink" href="#grundlagen" title="Link zu dieser Überschrift">¶</a></h2>
<p>Wir betrachten eine Zielfunktion <span class="math notranslate nohighlight">\(f:\mathbb{R} ^{d}\rightarrow \mathbb{R}\)</span>. Minimiert man</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f\)</span> über ganz <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>, so liegt ein
<em>nicht restringiertes</em> Problem vor</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> über <span class="math notranslate nohighlight">\(\emptyset \neq X\subset \mathbb{R} ^{d}\)</span>, so handelt es
sich um ein <em>restringiertes</em> Problem</p></li>
</ul>
<p>Ist <span class="math notranslate nohighlight">\(f(x) \ge c &gt; -\infty\)</span>, so existiert <span class="math notranslate nohighlight">\(f_\ast = \inf_x f\)</span>,
aber nicht notwendig ein <span class="math notranslate nohighlight">\(x_\ast\)</span> mit <span class="math notranslate nohighlight">\(f(x_\ast)=\inf_x f = f_\ast\)</span></p>
<p><strong>Beispiel:</strong></p>
<ul>
<li><p>für <span class="math notranslate nohighlight">\(f( x) =e^{-x^{2}}\)</span>, <span class="math notranslate nohighlight">\(x \in \mathbb{R}\)</span>, ist</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  \inf _{x\in \mathbb{R} }f\left( x\right) =0
  \end{equation*}\]</div>
<p>aber es gibt kein <span class="math notranslate nohighlight">\(x_{\ast }\in \mathbb{R}\)</span> mit
<span class="math notranslate nohighlight">\(f( x_{\ast }) =0\)</span>.</p>
</li>
</ul>
<p>Ist <span class="math notranslate nohighlight">\(f\)</span> stetig, <span class="math notranslate nohighlight">\(X\subset \mathbb{R} ^{d}\)</span> kompakt, dann hat das restringierte Problem (mindestens) eine Lösung, d.h.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
\text{argmin}_{x\in X}f(x) \neq \emptyset 
\end{equation*}\]</div>
</div>
<div class="section" id="nicht-restringierte-probleme">
<h2>Nicht restringierte Probleme<a class="headerlink" href="#nicht-restringierte-probleme" title="Link zu dieser Überschrift">¶</a></h2>
<p>Im nicht restringierten Fall erhält man bei (ausreichend oft) differenzierbarer Zielfunktion <span class="math notranslate nohighlight">\(f\)</span> notwendige und hinreichende Bedingungen für (lokale) Minimalstellen.</p>
<p>Ist <span class="math notranslate nohighlight">\(x_\ast \in \text{argmin}_{x\in \mathbb{R} ^{d}}f(x)\)</span>, dann gelten die notwendigen Bedingungen:</p>
<ul class="simple">
<li><p>ist <span class="math notranslate nohighlight">\(f\in C^{1}( \mathbb{R} ^{d})\)</span>
<span class="math notranslate nohighlight">\(\Rightarrow\)</span> <span class="math notranslate nohighlight">\(f'( x_{\ast }) =0\)</span></p></li>
<li><p>ist <span class="math notranslate nohighlight">\(f\in C^{2}( \mathbb{R} ^{d})\)</span>
<span class="math notranslate nohighlight">\(\Rightarrow\)</span> <span class="math notranslate nohighlight">\(f'( x_{\ast }) =0\)</span> und <span class="math notranslate nohighlight">\(f''( x_{\ast })\)</span> ist positiv semidefinit</p></li>
</ul>
<p>Als hinreichende Bedingungen erhalten wir für <span class="math notranslate nohighlight">\(f\in C^{2}( \mathbb{R} ^{d})\)</span>:</p>
<ul>
<li><p>ist <span class="math notranslate nohighlight">\(f'(\tilde{x}) =0\)</span> und <span class="math notranslate nohighlight">\(f''(\tilde{x})\)</span> positiv definit
oder <span class="math notranslate nohighlight">\(f''(x)\)</span> in einer offenen Umgebung <span class="math notranslate nohighlight">\(U\)</span> von <span class="math notranslate nohighlight">\(\tilde{x}\)</span> positiv semidefinit,
dann gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  \tilde{x} \in \text{argmin}_{x\in U}f(x), 
  \end{equation*}\]</div>
<p>d.h. <span class="math notranslate nohighlight">\(\tilde{x}\)</span> ist lokales Minimum</p>
</li>
</ul>
</div>
<div class="section" id="restringierte-probleme-lagrange-funktion-kkt-bedingungen">
<h2>Restringierte Probleme, Lagrange-Funktion, KKT-Bedingungen<a class="headerlink" href="#restringierte-probleme-lagrange-funktion-kkt-bedingungen" title="Link zu dieser Überschrift">¶</a></h2>
<p>Das Äquivalent zu den obigen Ergebnissen bei der restringierten Optimierung sind die
<a class="reference external" href="https://de.wikipedia.org/wiki/Karush-Kuhn-Tucker-Bedingungen"><em>Karush-Kuhn-Tucker-Bedingungen</em></a>.</p>
<p>Wir betrachten das Optimierungsproblem</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
\min _{x\in X}f(x),
\quad
g(x) \leq 0,
\quad
h(x) =0,
\end{equation*}\]</div>
<p>mit <span class="math notranslate nohighlight">\(\emptyset\neq X \subset \mathbb{R} ^{d}\)</span> und</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
f:X\rightarrow \mathbb{R} ,
\quad
g:X\rightarrow \mathbb{R} ^{m},
\quad
h:X\rightarrow \mathbb{R} ^{p}.
\end{equation*}\]</div>
<p>Wir nehmen an, dass <span class="math notranslate nohighlight">\(f,g,h \in C^1(X)\)</span> und definieren die zugehörige <em>Lagrange-Funktion</em> <span class="math notranslate nohighlight">\(L\)</span> durch</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
L\left( x,\lambda ,\mu \right) =f\left( x\right) +\lambda ^{T}g\left( x\right) +\mu ^{T}h\left( x\right). 
\end{equation*}\]</div>
<p><span class="math notranslate nohighlight">\(x_\ast,\lambda_\ast,\mu_\ast\)</span> heißt KKT-Punkt, falls</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
\begin{aligned}\partial _{x}L\left( x_{\ast },\lambda _{\ast },\mu _{\ast }\right) &amp;=0,\\ 
g\left( x_{\ast }\right) &amp;\leq 0\\ 
h\left( x_{\ast}\right) &amp;=0,\\ 
\lambda _{\ast } &amp;\geq 0,\\ 
\lambda _{\ast,i }g_i\left( x_{\ast }\right) &amp;=0 \quad \forall i\end{aligned}
\end{equation*}\]</div>
<p>Ist <span class="math notranslate nohighlight">\(x_\ast\)</span> eine Lösung des Optimierungsproblems und erfüllt gewisse Regularitätsbedingungen (Constraint-Qualifications), dann existieren <span class="math notranslate nohighlight">\(\lambda_\ast \geq 0, \mu_\ast\)</span>, so dass <span class="math notranslate nohighlight">\(x_\ast,\lambda_\ast,\mu_\ast\)</span> ein KKT-Punkt ist.
Wir haben es hier also mit notwendige Bedingungen zu tun.</p>
<p>Sind <span class="math notranslate nohighlight">\(X, f, g_i\)</span> konvex und <span class="math notranslate nohighlight">\(h\)</span> linear affin, dann vereinfacht sich das ganze noch:</p>
<ul>
<li><p>als Constraint-Qualification muss nur die
<em>Slater-Bedingung</em> gelten, d.h.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  \exists \tilde{x}\in X 
  \quad\text{mit}\quad
  g( \tilde{x}) &lt;0,
  \quad
  h( \tilde{x})=0
  \end{equation*}\]</div>
</li>
<li><p>KKT ist auch hinreichend, d.h.<span class="math notranslate nohighlight">\(x_\ast\)</span> ist lokales (und damit auch
globales) Minimum, ohne weitere Annahmen</p></li>
</ul>
<p><strong>Beispiel:</strong></p>
<ul>
<li><p>wir betrachten das Problem</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  \min_{x\in \mathbb{R}^{2},\ x_{1}^{2}+x_{2}^{2}\leq 1,\ x_{1}=x_{2}}x_1
  \end{equation*}\]</div>
</li>
<li><p>mit <span class="math notranslate nohighlight">\(X=\mathbb{R}^{2}\)</span>,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  f(x) = x_1, \quad g(x) = x_{1}^{2}+x_{2}^{2}-1, \quad h(x) = x_1 - x_2
  \end{equation*}\]</div>
<p>erhalten wir die Standardform</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  \min _{x\in X}f(x),
  \quad
  g(x) \leq 0,
  \quad
  h(x) =0
  \end{equation*}\]</div>
</li>
<li><p><span class="math notranslate nohighlight">\(X,f,g\)</span> sind konvex, <span class="math notranslate nohighlight">\(h\)</span> ist linear affin und die Slater-Bedingung ist ebenfalls erfüllt</p></li>
<li><p>als Lagrange-Funktion erhalten wir</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  L(x,\lambda,\mu) = x_1 + \lambda(x_{1}^{2}+x_{2}^{2}-1) + \mu (x_1 - x_2)
  \end{equation*}\]</div>
<p>und somit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
  \partial_{x}L(x,\lambda ,\mu) &amp;=
  \begin{pmatrix} 1 +2\lambda x_{1} +\mu \\ 2\lambda x_{2} -\mu \end{pmatrix} =0, \\
  g\left( x\right) &amp;=x_{1}^{2}+x_{2}^{2}-1\leq 0,\\ 
  h\left( x\right) &amp;=x_{1}-x_{2}=0,\\ 
  \lambda g\left( x\right) &amp;=\lambda \left( x_{1}^{2}+x_{2}^{2}-1\right) =0
  \end{align*}\]</div>
</li>
<li><p>subtrahiert man im Gradienten die zweite von der ersten Gleichung, so folgt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  1+2\lambda \left( x_{1}-x_{2}\right) +2\mu =0
  \end{equation*}\]</div>
<p>und wegen <span class="math notranslate nohighlight">\(x_{1}-x_{2}=0\)</span> schließlich</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  \mu =-\dfrac{1}{2}
  \end{equation*}\]</div>
</li>
<li><p>eingesetzt in die zweite Komponente des Gradienten erhalten wir</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  \lambda x_{2}=\dfrac{\mu }{2}=-\dfrac{1}{4}
  \end{equation*}\]</div>
</li>
<li><p>aus <span class="math notranslate nohighlight">\(\lambda \geq 0\)</span> folgt daraus <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span> und</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
    x_2 &lt; 0
    \end{equation*}\]</div>
<p>und wegen <span class="math notranslate nohighlight">\(\lambda \left( x_{1}^{2}+x_{2}^{2}-1\right) =0\)</span> somit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
    x_{1}^{2}+x_{2}^{2} = 1
    \end{equation*}\]</div>
</li>
<li><p>außerdem soll noch die Gleichheitsbedingung</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  x_1 = x_2
  \end{equation*}\]</div>
<p>gelten</p>
</li>
<li><p>insgesamt erhalten wir damit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  x_{2}=-\dfrac{1}{\sqrt{2}}
  \end{equation*}\]</div>
<p>und somit ist</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  x_{\ast }=-\dfrac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1 \end{pmatrix}
  \end{equation*}\]</div>
<p>wegen der Konvexität und der Slater-Bedingung die (eindeutige) Lösung des Optimierungsproblems</p>
</li>
</ul>
<p>Im nicht-konvexen Fall gelten für <span class="math notranslate nohighlight">\(f,g,h \in C^2\)</span> folgende hinreichende Bedingungen:</p>
<ul>
<li><p>ist <span class="math notranslate nohighlight">\(x_\ast,\lambda_\ast,\mu_\ast\)</span> ein KKT-Punkt und gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  s^{T}\partial _{x}^{2}L\left( x_{\ast },\lambda _{\ast },\mu_\ast \right) s\geq 0
  \end{equation*}\]</div>
<p>für alle <span class="math notranslate nohighlight">\(s\neq 0\)</span> mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  \begin{pmatrix} 
  \partial _{x}g_{i}\left( x_{\ast }\right) \\     
  \partial _{x}h_{j}\left( x_{\ast }\ \right)
  \end{pmatrix}^{T}
  s=0
  \end{equation*}\]</div>
<p>mit <span class="math notranslate nohighlight">\(i\)</span> s.d. <span class="math notranslate nohighlight">\(\lambda_{\ast,i}&gt;0\)</span>,
dann ist <span class="math notranslate nohighlight">\(x_\ast\)</span> ein lokales Minimum</p>
</li>
</ul>
</div>
<div class="section" id="dualitat">
<h2>Dualität<a class="headerlink" href="#dualitat" title="Link zu dieser Überschrift">¶</a></h2>
<p>Wir betrachten das primale Problem</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
\min _{x\in X}f(x),
\quad
g(x) \leq 0,
\quad
h(x) =0,
\end{equation*}\]</div>
<p>die zugehörige Lagrange-Funktion</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
L( x,\lambda ,\mu ) 
= f(x) +\lambda ^{T}g(x) +\mu ^{T}h(x) 
\end{equation*}\]</div>
<p>und definieren damit die <em>duale Funktion</em></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
q( \lambda ,\mu ) =\inf _{x\in X} L( x,\lambda ,\mu ). 
\end{equation*}\]</div>
<p>Für <span class="math notranslate nohighlight">\(q\)</span> untersuchen wir das duale Problem</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
\max_{\lambda \geq 0,\mu }q( \lambda ,\mu )
\end{equation*}\]</div>
<p>über dem <em>wesentlichen Zulässigkeitsbereich</em></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
\mathrm{dom}_{q}=\big\{ ( \lambda ,\mu )\ \big|\  \lambda \geq 0,\ q( \lambda ,\mu ) &gt;-\infty \big\}
\end{equation*}\]</div>
<p>Das duale Problem hat folgende Eigenschaften:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathrm{dom}_{q}\)</span> ist immer konvex</p></li>
<li><p><span class="math notranslate nohighlight">\(-q\)</span> ist immer konvex</p></li>
<li><p>ist</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
    R_{p}=\big\{ x \ \big| \ g( x) \leq 0,h( x) = 0\big\} 
    \end{equation*}\]</div>
<p>der zulässige Bereich des primalen Problems, dann gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
    \sup_{\mathrm{dom}_{q}} q\left( \lambda ,\mu \right) \leq \inf_{R_{p}} f( x)
    \end{equation*}\]</div>
<p>und somit gilt für alle Lösungen <span class="math notranslate nohighlight">\(\lambda_\ast, \mu_\ast\)</span> von
<span class="math notranslate nohighlight">\(\sup_{\mathrm{dom}_{q}} q\left( \lambda ,\mu \right)\)</span> und <span class="math notranslate nohighlight">\(x_\ast\)</span>
von <span class="math notranslate nohighlight">\(\inf_{R_{p}} f( x)\)</span></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
    q(\lambda_\ast, \mu_\ast) \leq f(x_\ast).
    \end{equation*}\]</div>
</li>
</ul>
<p>Die Differenz</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
f(x_\ast) - q(\lambda_\ast, \mu_\ast) \ge 0
\end{equation*}\]</div>
<p>bezeichnet man als <em>Dualitäts-Lücke</em>.
Gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
f(x_\ast) - q(\lambda_\ast, \mu_\ast) = 0
\end{equation*}\]</div>
<p>so spricht man von starker Dualität:</p>
<ul class="simple">
<li><p>starke Dualität gilt nicht immer</p></li>
<li><p>sind <span class="math notranslate nohighlight">\(f,g\)</span> konvex, <span class="math notranslate nohighlight">\(h\)</span> linear affin und die Slater-Bedingung erfüllt,
dann gilt starke Dualität</p></li>
</ul>
<p>Praktischer Einsatz:</p>
<ul>
<li><p>ist nur der Wert <span class="math notranslate nohighlight">\(f_\ast = f(x_\ast)\)</span> (und nicht <span class="math notranslate nohighlight">\(x_\ast\)</span>) interessant,
dann kann man statt des primalen das duale Problem lösen, das immer konvex ist</p></li>
<li><p>ist <span class="math notranslate nohighlight">\(\bar{x}\)</span> eine Näherung von <span class="math notranslate nohighlight">\(x_\ast\)</span> und gilt starke Dualität, so kann man mit Hilfe geeignet gewählter <span class="math notranslate nohighlight">\(\bar{\lambda},\bar{\mu}\)</span> über</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  f(\bar{x}) - q(\bar{\lambda},\bar{\mu})
  \end{equation*}\]</div>
<p>einen Fehlerindikator für <span class="math notranslate nohighlight">\(\bar{x}\)</span> berechnen</p>
</li>
</ul>
<p><strong>Beispiel:</strong></p>
<ul>
<li><p>wir betrachten</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  \min _{x\in \mathbb{R} ^{d}} c^{T}x,
  \quad Ax-b\leq 0,
  \quad A\in \mathbb{R} ^{m\times d}
  \end{equation*}\]</div>
</li>
<li><p>als Lagrange-Funktion erhalten wir mit <span class="math notranslate nohighlight">\(\lambda \in \mathbb{R}^m\)</span>,
<span class="math notranslate nohighlight">\(\lambda \geq 0\)</span></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} 
  L(x,\lambda) 
  &amp;= c^{T}x+\lambda ^{T}( Ax-b) \\
  &amp;=( c^{T}+\lambda ^{T}A) x - \lambda ^{T}b
  \end{align*}\]</div>
<p>bzw. mit <span class="math notranslate nohighlight">\(y = c + A^T \lambda\)</span></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} 
  L(x,\lambda) 
  &amp;=y^T x - \lambda ^{T}b  
  \end{align*}\]</div>
</li>
<li><p>jetzt berechnen wir die duale Funktion</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  q(\lambda) =\inf _{x\in \mathbb{R}^d} L( x, \lambda) 
  \end{equation*}\]</div>
</li>
<li><p><span class="math notranslate nohighlight">\(L\)</span> ist linear affin in <span class="math notranslate nohighlight">\(x\)</span> mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
    \partial_x L(x,\lambda) = y^T
    \end{equation*}\]</div>
</li>
<li><p>ist <span class="math notranslate nohighlight">\(y \neq 0\)</span> so erhalten wir mit <span class="math notranslate nohighlight">\(x = \nu y\)</span></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
      L(x,\lambda) 
      = \nu \|y\|_2^2 - \lambda ^{T}b   
      \xrightarrow{\nu\to-\infty}-\infty
    \end{equation*}\]</div>
</li>
<li><p>für <span class="math notranslate nohighlight">\(y=0\)</span> (also <span class="math notranslate nohighlight">\(\partial_x L(x,\lambda) = 0\)</span>)
gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
      L(x,\lambda) 
      = - \lambda ^{T}b
      = \inf _{x\in \mathbb{R}^d} L( x, \lambda) 
    \end{equation*}\]</div>
</li>
<li><p>somit ist</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  q(\lambda) 
  =\begin{cases}
  -\lambda ^{T}b &amp; \text{für }c + A^T \lambda=0\\ 
  -\infty &amp; \text{sonst}\end{cases}
  \end{equation*}\]</div>
<p>und das duale Problem hat die Form</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
  \max_{\lambda \in \mathbb{R} ^{m}}(-\lambda ^{T}b),
  \quad \lambda \geq 0,
  \quad A^{T}\lambda =-c
  \end{equation*}\]</div>
</li>
</ul>
<p><strong>Beispiel:</strong></p>
<ul>
<li><p>wir leiten jetzt die duale Form des Optimierungsproblems
bei Support-Vector Classifiern her, die wir oben im Zusammenhang mit
dem Kernel-Trick benutzt haben</p></li>
<li><p>das primale Problem lautet</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
    \min_{v\neq 0, v_0,\xi}
    \Big(
    \frac{1}{2}\|v\|_2^2
    + C \sum_{i=1}^n \xi_i
    \Big)
    \end{equation*}\]</div>
<p>mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
    y_i(v^T x_i + v_0)  \geq 1 - \xi_i, 
    \quad
    \xi_i\geq 0,
    \quad i = 1,\ldots,n.
    \end{equation*}\]</div>
</li>
<li><p>setzen wir</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} 
    w 
    &amp;= (v,v_0,\xi) \in X = \mathbb{R}^{m + 1 + n} \\
    f(w) 
    &amp;= \frac{1}{2}\|v\|_2^2 + C \sum_{i=1}^n \xi_i \\
    g_i(w) 
    &amp;= -\Big(y_i \big(\sum_{j=1}^m v_j x_{ij} + v_0 \big) - 1 + \xi_i \Big),   
    \quad i=1,\ldots,n\\
    g_i(w) 
    &amp;= - \xi_i, 
    \quad i=n+1,\ldots,2n
    \end{align*}\]</div>
<p>so erhalten wir die Standardform</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} 
   \min _{w\in \mathbb{R}^{m + 1 + n}}f(w),
    \quad
    g(w) \leq 0
    \end{align*}\]</div>
</li>
</ul>
<ul>
<li><p>mit <span class="math notranslate nohighlight">\(\lambda = (\alpha, \beta)\)</span>, <span class="math notranslate nohighlight">\(\alpha,\beta \geq 0\)</span>, folgt für
die Lagrange-Funktion</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} 
    L(w,\lambda) =&amp;
    L(v, v_0, \xi, \alpha, \beta) \\
    = &amp;
    \frac{1}{2}\|v\|_2^2
    + C \sum_{i=1}^n \xi_i
    \\
    &amp;- \sum_{i=1}^n \alpha_i  \Big(y_i \big(\sum_{j=1}^m v_j x_{ij} + v_0 \big) - 1 + \xi_i \Big)\\
    &amp;- \sum_{i=1}^n\beta_i \xi_i\\
    = &amp;
    \frac{1}{2}\|v\|_2^2
    - \sum_{i=1}^n \alpha_i y_i \sum_{j=1}^m v_j x_{ij} 
    \\
    &amp;- v_0\sum_{i=1}^n \alpha_i  y_i 
    \\
    &amp;+ \sum_{i=1}^n (C-\alpha_i - \beta_i) \xi_i 
    \\
    &amp;+ \sum_{i=1}^n \alpha_i
    \end{align*}\]</div>
<p>bzw. für die duale Funktion</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} 
    q(\alpha,\beta) 
    = \inf_{(v, v_0, \xi)\in \mathbb{R}^{m + 1 + n}} L(v, v_0, \xi, \alpha, \beta) 
    \end{align*}\]</div>
</li>
</ul>
<ul>
<li><p><span class="math notranslate nohighlight">\(L\)</span> ist quadratisch in <span class="math notranslate nohighlight">\(v\)</span> und linear affin in <span class="math notranslate nohighlight">\(v_0\)</span>
und <span class="math notranslate nohighlight">\(\xi\)</span> (und somit konvex und differenzierbar)</p></li>
<li><p>wie im vorherigen Beispiel folgt, dass <span class="math notranslate nohighlight">\(q(\alpha,\beta)\)</span>
nur dann größer <span class="math notranslate nohighlight">\(-\infty\)</span> sein kann, wenn</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    0 = \partial_{v_0} L(v, v_0, \xi, \alpha, \beta) 
    &amp;= - \sum_{i=1}^n \alpha_i y_i, 
    \\
    0 = \partial_{\xi_i} L(v, v_0, \xi, \alpha, \beta) 
    &amp;= 
    C - \alpha_i - \beta_i,
    \quad i = 1,\ldots,n,
    \end{align*}\]</div>
<p>gilt, insgesamt also</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
  \alpha_i,\beta_i\geq 0,
  \quad
  \sum_{i=1}^n \alpha_i y_i = 0, 
  \quad
  \alpha_i + \beta_i = C
  \end{align*}\]</div>
</li>
</ul>
<ul>
<li><p>unter diesen Einschränkungen vereinfacht sich <span class="math notranslate nohighlight">\(L\)</span> zu</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} 
    L(v, v_0, \xi, \alpha, \beta)
    =
    \frac{1}{2}\|v\|_2^2
    - \sum_{i=1}^n \alpha_i y_i \sum_{j=1}^m v_j x_{ij} 
    &amp;+ \sum_{i=1}^n \alpha_i,
    \end{align*}\]</div>
<p>ist also insbesondere unabhängig von <span class="math notranslate nohighlight">\(v_0, \xi, \beta\)</span>
und wird bei gegebenem <span class="math notranslate nohighlight">\(\alpha\)</span> minimal an <span class="math notranslate nohighlight">\(\hat{v}\)</span> mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    0 = \partial_{v_k} L(\hat{v}, v_0, \xi, \alpha, \beta) 
    &amp;= 
    \hat{v}_k
    - \sum_{i=1}^n \alpha_i y_i x_{ik},
    \quad k = 1,\ldots,m,
    \end{align*}\]</div>
<p>also</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
  \hat{v}_k &amp;= \sum_{i=1}^n \alpha_i y_i x_{ik}.\\
  \end{align*}\]</div>
</li>
</ul>
<ul>
<li><p>eingesetzt in <span class="math notranslate nohighlight">\(L\)</span> erhalten wir damit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} 
    q(\alpha,\beta) 
    &amp; =   L(\hat{v}, v_0, \xi, \alpha, \beta)
    \\
    &amp; = 
    \frac{1}{2}\|\hat{v}\|_2^2
    - \sum_{i=1}^n \alpha_i y_i \sum_{j=1}^m \hat{v}_j x_{ij} 
    + \sum_{i=1}^n \alpha_i
    \\
    &amp; =
    \frac{1}{2}\sum_{j=1}^m \hat{v}_j^2
    - \sum_{j=1}^m \hat{v}_j\sum_{i=1}^n \alpha_i y_i  x_{ij} 
      +  \sum_{i=1}^n \alpha_i 
      \\
    &amp; =
    \frac{1}{2}\sum_{j=1}^m \hat{v}_j^2
     - \sum_{j=1}^m \hat{v}_j^2
      +  \sum_{i=1}^n \alpha_i 
      \\
    &amp; =
    -\frac{1}{2}\sum_{j=1}^m \hat{v}_j^2
      +  \sum_{i=1}^n \alpha_i 
      \\
    &amp; =
    -\frac{1}{2}
    \sum_{j=1}^m \big(\sum_{i=1}^n \alpha_i y_i  x_{ij} \big)^2
      +  \sum_{i=1}^n \alpha_i \\
    &amp; =
    -\frac{1}{2}
    \sum_{i=1}^n \sum_{k=1}^n 
    \alpha_i y_i 
    \big( \sum_{j=1}^m x_{ij} x_{kj}\big)
    y_k\alpha_k 
     +  \sum_{i=1}^n \alpha_i 
    \end{align*}\]</div>
<p>bzw.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
    q(\alpha,\beta) =
    -\frac{1}{2}\alpha^T Q \alpha + e^T \alpha 
    \end{equation*}\]</div>
<p>mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} 
    Q = \big( y_i x_i^T x_k y_k \big)_{i,k = 1,\ldots,n},
    \quad
    e = (1,\ldots,1)^T
    \end{align*}\]</div>
</li>
</ul>
<ul>
<li><p>insgesamt erhalten wir für die duale Funktion <span class="math notranslate nohighlight">\(q\)</span> für
<span class="math notranslate nohighlight">\(\alpha,\beta\geq 0\)</span></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
  q(\alpha,\beta) 
  =
  \begin{cases}
      -\frac{1}{2}\alpha^T Q \alpha + e^T \alpha 
      &amp; \text{für} \quad y^T\alpha = 0, \quad \alpha + \beta = Ce \\
      - \infty &amp; \text{sonst}
  \end{cases}
  \end{align*}\]</div>
</li>
</ul>
<ul>
<li><p>als duales Problem haben wir damit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
  \max_{\alpha\geq 0, \beta\geq 0}q(\alpha,\beta)
  = \min_{\alpha\geq 0} 
    \big(\frac{1}{2}\alpha^T Q \alpha - e^T \alpha \big)
  \end{align*}\]</div>
<p>unter den Nebenbedingungen</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
  y^T \alpha = 0,
  \quad \alpha_i + \beta_i = C \quad \forall i
  \end{align*}\]</div>
</li>
<li><p>da <span class="math notranslate nohighlight">\(\beta_i \geq 0\)</span> nur in die Nebenbedingung eingeht,
kann diese auf <span class="math notranslate nohighlight">\(0\leq \alpha_i \leq C\)</span> geändert werden</p></li>
<li><p>somit erhalten wir die finale Form des dualen Problems,
wie wir sie bei den Support-Vector Classifiern bereits
benutzt haben:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
    \min_{\alpha \geq 0}
    \Big(
    \frac{1}{2}\alpha^T Q \alpha - e^T \alpha 
    \Big)
    \end{equation*}\]</div>
<p>mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*} 
    Q = \big( y_i x_i^T x_jy_j \big)_{i,j = 1,\ldots,n},
    \quad
    y^T \alpha = 0,
    \quad
    0\leq \alpha \leq Ce.
    \end{equation*}\]</div>
</li>
</ul>
</div>
<div class="section" id="zusammenfassung">
<h2>Zusammenfassung<a class="headerlink" href="#zusammenfassung" title="Link zu dieser Überschrift">¶</a></h2>
<p>Für nicht-restringierte bzw, restringierte Optimierungsprobleme haben wir die Werkzeuge
aus der Analysis betrachtet, u.a. Lagrange-Funktion, KKT-Bedingungen und duale Probleme.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="07_Topic_Extraction.html" title="zurück Seite">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">zurück</p>
            <p class="prev-next-title">Topic Extraction, NMF</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="09_Konvexitaet.html" title="weiter Seite">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">weiter</p>
        <p class="prev-next-title">Konvexität</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      Durch Martin Reißel<br/>
    
        &copy; Urheberrechte © 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>